{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "!kaggle competitions download -c spaceship-titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321.. connected.\n",
      "Warning: Your H2O cluster version is (3 months and 25 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 23 hours 45 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 25 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_kevin_qgh2wf</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.887 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 day 23 hours 45 mins\n",
       "H2O_cluster_timezone:       America/Los_Angeles\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    3 months and 25 days\n",
       "H2O_cluster_name:           H2O_from_python_kevin_qgh2wf\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.887 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.9 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Rows:8693\n",
       "Cols:14\n",
       "</pre>"
      ],
      "text/plain": [
       "Rows:8693\n",
       "Cols:14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>       </th><th>PassengerId  </th><th>HomePlanet  </th><th>CryoSleep  </th><th>Cabin  </th><th>Destination  </th><th>Age              </th><th>VIP  </th><th>RoomService       </th><th>FoodCourt         </th><th>ShoppingMall      </th><th>Spa               </th><th>VRDeck            </th><th>Name              </th><th>Transported  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string       </td><td>enum        </td><td>enum       </td><td>enum   </td><td>enum         </td><td>int              </td><td>enum </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>string            </td><td>enum         </td></tr>\n",
       "<tr><td>mins   </td><td>NaN          </td><td>            </td><td>           </td><td>       </td><td>             </td><td>0.0              </td><td>     </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>NaN               </td><td>             </td></tr>\n",
       "<tr><td>mean   </td><td>NaN          </td><td>            </td><td>           </td><td>       </td><td>             </td><td>28.82793046746535</td><td>     </td><td>224.68761748120303</td><td>458.07720329024676</td><td>173.72916912197996</td><td>311.1387779083431 </td><td>304.8547912992357 </td><td>NaN               </td><td>             </td></tr>\n",
       "<tr><td>maxs   </td><td>NaN          </td><td>            </td><td>           </td><td>       </td><td>             </td><td>79.0             </td><td>     </td><td>14327.0           </td><td>29813.0           </td><td>23492.0           </td><td>22408.0           </td><td>24133.0           </td><td>NaN               </td><td>             </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN          </td><td>            </td><td>           </td><td>       </td><td>             </td><td>14.48902142390878</td><td>     </td><td>666.7176629280652 </td><td>1611.489240355072 </td><td>604.6964584708243 </td><td>1136.7055348344065</td><td>1145.7171888056614</td><td>NaN               </td><td>             </td></tr>\n",
       "<tr><td>zeros  </td><td>0            </td><td>            </td><td>           </td><td>       </td><td>             </td><td>178              </td><td>     </td><td>5577              </td><td>5456              </td><td>5587              </td><td>5324              </td><td>5495              </td><td>0                 </td><td>             </td></tr>\n",
       "<tr><td>missing</td><td>0            </td><td>201         </td><td>217        </td><td>199    </td><td>182          </td><td>179              </td><td>203  </td><td>181               </td><td>183               </td><td>208               </td><td>183               </td><td>188               </td><td>200               </td><td>0            </td></tr>\n",
       "<tr><td>0      </td><td>0001_01      </td><td>Europa      </td><td>False      </td><td>B/0/P  </td><td>TRAPPIST-1e  </td><td>39.0             </td><td>False</td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>Maham Ofracculy   </td><td>False        </td></tr>\n",
       "<tr><td>1      </td><td>0002_01      </td><td>Earth       </td><td>False      </td><td>F/0/S  </td><td>TRAPPIST-1e  </td><td>24.0             </td><td>False</td><td>109.0             </td><td>9.0               </td><td>25.0              </td><td>549.0             </td><td>44.0              </td><td>Juanna Vines      </td><td>True         </td></tr>\n",
       "<tr><td>2      </td><td>0003_01      </td><td>Europa      </td><td>False      </td><td>A/0/S  </td><td>TRAPPIST-1e  </td><td>58.0             </td><td>True </td><td>43.0              </td><td>3576.0            </td><td>0.0               </td><td>6715.0            </td><td>49.0              </td><td>Altark Susent     </td><td>False        </td></tr>\n",
       "<tr><td>3      </td><td>0003_02      </td><td>Europa      </td><td>False      </td><td>A/0/S  </td><td>TRAPPIST-1e  </td><td>33.0             </td><td>False</td><td>0.0               </td><td>1283.0            </td><td>371.0             </td><td>3329.0            </td><td>193.0             </td><td>Solam Susent      </td><td>False        </td></tr>\n",
       "<tr><td>4      </td><td>0004_01      </td><td>Earth       </td><td>False      </td><td>F/1/S  </td><td>TRAPPIST-1e  </td><td>16.0             </td><td>False</td><td>303.0             </td><td>70.0              </td><td>151.0             </td><td>565.0             </td><td>2.0               </td><td>Willy Santantines </td><td>True         </td></tr>\n",
       "<tr><td>5      </td><td>0005_01      </td><td>Earth       </td><td>False      </td><td>F/0/P  </td><td>PSO J318.5-22</td><td>44.0             </td><td>False</td><td>0.0               </td><td>483.0             </td><td>0.0               </td><td>291.0             </td><td>0.0               </td><td>Sandie Hinetthews </td><td>True         </td></tr>\n",
       "<tr><td>6      </td><td>0006_01      </td><td>Earth       </td><td>False      </td><td>F/2/S  </td><td>TRAPPIST-1e  </td><td>26.0             </td><td>False</td><td>42.0              </td><td>1539.0            </td><td>3.0               </td><td>0.0               </td><td>0.0               </td><td>Billex Jacostaffey</td><td>True         </td></tr>\n",
       "<tr><td>7      </td><td>0006_02      </td><td>Earth       </td><td>True       </td><td>G/0/S  </td><td>TRAPPIST-1e  </td><td>28.0             </td><td>False</td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>nan               </td><td>Candra Jacostaffey</td><td>True         </td></tr>\n",
       "<tr><td>8      </td><td>0007_01      </td><td>Earth       </td><td>False      </td><td>F/3/S  </td><td>TRAPPIST-1e  </td><td>35.0             </td><td>False</td><td>0.0               </td><td>785.0             </td><td>17.0              </td><td>216.0             </td><td>0.0               </td><td>Andona Beston     </td><td>True         </td></tr>\n",
       "<tr><td>9      </td><td>0008_01      </td><td>Europa      </td><td>True       </td><td>B/1/P  </td><td>55 Cancri e  </td><td>14.0             </td><td>False</td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>Erraiam Flatic    </td><td>True         </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[8693 rows x 14 columns]</pre>"
      ],
      "text/plain": [
       "         PassengerId    HomePlanet    CryoSleep    Cabin    Destination    Age                VIP    RoomService         FoodCourt           ShoppingMall        Spa                 VRDeck              Name                Transported\n",
       "-------  -------------  ------------  -----------  -------  -------------  -----------------  -----  ------------------  ------------------  ------------------  ------------------  ------------------  ------------------  -------------\n",
       "type     string         enum          enum         enum     enum           int                enum   int                 int                 int                 int                 int                 string              enum\n",
       "mins     NaN                                                               0.0                       0.0                 0.0                 0.0                 0.0                 0.0                 NaN\n",
       "mean     NaN                                                               28.82793046746535         224.68761748120303  458.07720329024676  173.72916912197996  311.1387779083431   304.8547912992357   NaN\n",
       "maxs     NaN                                                               79.0                      14327.0             29813.0             23492.0             22408.0             24133.0             NaN\n",
       "sigma    NaN                                                               14.48902142390878         666.7176629280652   1611.489240355072   604.6964584708243   1136.7055348344065  1145.7171888056614  NaN\n",
       "zeros    0                                                                 178                       5577                5456                5587                5324                5495                0\n",
       "missing  0              201           217          199      182            179                203    181                 183                 208                 183                 188                 200                 0\n",
       "0        0001_01        Europa        False        B/0/P    TRAPPIST-1e    39.0               False  0.0                 0.0                 0.0                 0.0                 0.0                 Maham Ofracculy     False\n",
       "1        0002_01        Earth         False        F/0/S    TRAPPIST-1e    24.0               False  109.0               9.0                 25.0                549.0               44.0                Juanna Vines        True\n",
       "2        0003_01        Europa        False        A/0/S    TRAPPIST-1e    58.0               True   43.0                3576.0              0.0                 6715.0              49.0                Altark Susent       False\n",
       "3        0003_02        Europa        False        A/0/S    TRAPPIST-1e    33.0               False  0.0                 1283.0              371.0               3329.0              193.0               Solam Susent        False\n",
       "4        0004_01        Earth         False        F/1/S    TRAPPIST-1e    16.0               False  303.0               70.0                151.0               565.0               2.0                 Willy Santantines   True\n",
       "5        0005_01        Earth         False        F/0/P    PSO J318.5-22  44.0               False  0.0                 483.0               0.0                 291.0               0.0                 Sandie Hinetthews   True\n",
       "6        0006_01        Earth         False        F/2/S    TRAPPIST-1e    26.0               False  42.0                1539.0              3.0                 0.0                 0.0                 Billex Jacostaffey  True\n",
       "7        0006_02        Earth         True         G/0/S    TRAPPIST-1e    28.0               False  0.0                 0.0                 0.0                 0.0                 nan                 Candra Jacostaffey  True\n",
       "8        0007_01        Earth         False        F/3/S    TRAPPIST-1e    35.0               False  0.0                 785.0               17.0                216.0               0.0                 Andona Beston       True\n",
       "9        0008_01        Europa        True         B/1/P    55 Cancri e    14.0               False  0.0                 0.0                 0.0                 0.0                 0.0                 Erraiam Flatic      True\n",
       "[8693 rows x 14 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "trainRaw = h2o.import_file('train.csv')\n",
    "testRaw = h2o.import_file('test.csv')\n",
    "\n",
    "trainRaw.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "trainRawDF = pd.read_csv('train.csv')\n",
    "testRawDF = pd.read_csv('test.csv')\n",
    "def curate(df):\n",
    "    df[['Deck', 'CabinNum', 'Side']] = df['Cabin'].str.split('/', expand=True, n=3)\n",
    "    df['CabinNumLen'] = df['CabinNum'].str.len()\n",
    "    df['CabinNum'] = pd.to_numeric(df['CabinNum'], errors='coerce')\n",
    "    df['CabinRegion'] = pd.qcut(df['CabinNum'], q=7)\n",
    "    df['AgeDecile'] = pd.qcut(df['Age'], q=10)\n",
    "\n",
    "    df[['FirstName', 'LastName']] = df['Name'].str.split(' ', expand=True, n=2)\n",
    "    df['GroupNum'] = df['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "\n",
    "    df['FamilySize'] = df.groupby(['LastName'])['LastName'].transform('size')\n",
    "    df['GroupSize'] = df.groupby(['GroupNum'])['GroupNum'].transform('size')\n",
    "    df['CabinSize'] = df.groupby(['CabinNum'])['CabinNum'].transform('size')\n",
    "\n",
    "    df['GroupSize'] = df.groupby(['GroupNum'])['GroupNum'].transform('size')\n",
    "    df['CabinSize'] = df.groupby(['CabinNum'])['CabinNum'].transform('size') \n",
    "\n",
    "    df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(0, inplace=True)\n",
    "    df['Expenditure'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n",
    "    df['LogExpenditure'] = np.log(df['Expenditure'] + 1)\n",
    "    df['ZeroExpense'] = df['Expenditure'] == 0\n",
    "    return df\n",
    "\n",
    "trainProcessedDF = curate(trainRawDF)\n",
    "testProcessedDF = curate(testRawDF)\n",
    "\n",
    "print(trainProcessedDF.shape)\n",
    "trainProcessedDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n",
      "PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def countNan(df):\n",
    "    nan_counts_column = df.isna().sum()\n",
    "    print(nan_counts_column)\n",
    "\n",
    "def impute(df):\n",
    "    # HOME_PLANET\n",
    "    # Decks A, B, C or T came from Europa. Deck G came from Earth\n",
    "    df.loc[(df['HomePlanet'].isna()) & (df['Cabin_deck'].isin(['A', 'B', 'C', 'T'])), 'HomePlanet']='Europa'\n",
    "    df.loc[(df['HomePlanet'].isna()) & (df['Cabin_deck']=='G'), 'HomePlanet']='Earth'\n",
    "    # Surnames have the same HomePlanet\n",
    "    SHP_gb=df.groupby(['Surname','HomePlanet'])['HomePlanet'].size().unstack().fillna(0)\n",
    "    SHP_index=df[df['HomePlanet'].isna()][(df[df['HomePlanet'].isna()]['Surname']).isin(SHP_gb.index)].index\n",
    "    df.loc[SHP_index,'HomePlanet']=df.iloc[SHP_index,:]['Surname'].map(lambda x: SHP_gb.idxmax(axis=1)[x])\n",
    "    # For the rest, let's set source=Earth\n",
    "    df.loc[(df['HomePlanet'].isna()), 'Destination']='Earth'\n",
    "\n",
    "    df.loc[(df['Destination'].isna()), 'Destination']='TRAPPIST-1e'\n",
    "\n",
    "    # NAME / FAMILY SIZE - what does this code do..?\n",
    "    GSN_gb=df[df['Group_size']>1].groupby(['Group','Surname'])['Surname'].size().unstack().fillna(0)\n",
    "\n",
    "    df['Family_size']=df['Surname'].map(lambda x: df['Surname'].value_counts()[x])\n",
    "    df.loc[df['Surname']=='Unknown','Surname']=np.nan\n",
    "    df.loc[df['Family_size']>100,'Family_size']=0\n",
    "    GSN_index=df[df['Surname'].isna()][(df[df['Surname'].isna()]['Group']).isin(GSN_gb.index)].index\n",
    "    df.loc[GSN_index,'Surname']=df.iloc[GSN_index,:]['Group'].map(lambda x: GSN_gb.idxmax(axis=1)[x])\n",
    "\n",
    "    # CABIN\n",
    "    GCD_gb=df[df['Group_size']>1].groupby(['Group','Cabin_deck'])['Cabin_deck'].size().unstack().fillna(0)\n",
    "    GCN_gb=df[df['Group_size']>1].groupby(['Group','Cabin_number'])['Cabin_number'].size().unstack().fillna(0)\n",
    "    GCS_gb=df[df['Group_size']>1].groupby(['Group','Cabin_side'])['Cabin_side'].size().unstack().fillna(0)\n",
    "\n",
    "    # Passengers with missing cabin side, in a group with known cabin side.\n",
    "    GCS_index=df[df['Cabin_side'].isna()][(df[df['Cabin_side'].isna()]['Group']).isin(GCS_gb.index)].index\n",
    "    df.loc[GCS_index,'Cabin_side']=df.iloc[GCS_index,:]['Group'].map(lambda x: GCS_gb.idxmax(axis=1)[x])\n",
    "\n",
    "    # VIP = Mode\n",
    "    df.loc[df['VIP'].isna(),'VIP']=False\n",
    "\n",
    "    # AGE = median of each subgroup\n",
    "    na_rows_A=df.loc[df['Age'].isna(),'Age'].index\n",
    "    df.loc[df['Age'].isna(),'Age']=df.groupby(['HomePlanet','No_spending','Solo','Cabin_deck'])['Age'].transform(lambda x: x.fillna(x.median()))[na_rows_A]\n",
    "\n",
    "    # CRYOSLEEP\n",
    "    df['CryoSleep']\n",
    "    na_rows_CSL=df.loc[df['CryoSleep'].isna(),'CryoSleep'].index\n",
    "    df.loc[df['CryoSleep'].isna(),'CryoSleep']=df.groupby(['No_spending'])['CryoSleep'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))[na_rows_CSL]\n",
    "\n",
    "    # EXPENDITURES\n",
    "    for col in exp_feats:\n",
    "        data.loc[(data[col].isna()) & (data['CryoSleep']==True), col]=0\n",
    "\n",
    "    df['RoomService']\n",
    "    df['FoodCourt']\n",
    "    df['ShoppingMall']\n",
    "    df['Spa']\n",
    "    df['VRDeck']\n",
    "\n",
    "    return df\n",
    "\n",
    "trainRawDF = pd.read_csv('train.csv')\n",
    "testRawDF = pd.read_csv('test.csv')\n",
    "\n",
    "countNan(trainRawDF)\n",
    "trainProcessedDF = impute(trainRawDF)\n",
    "countNan(trainRawDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = trainProcessedDF[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].corr()\n",
    "print(corr_matrix)\n",
    "print(trainProcessedDF.nunique())\n",
    "print(trainProcessedDF.dtypes)\n",
    "print(trainProcessedDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(trainRawDF, hue='Transported', kind='kde', corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericScatterPlots(df, numericList, colorLabel):\n",
    "    comboList = []\n",
    "    for i in range(len(numericList)):\n",
    "        for j in range(i+1, len(numericList)):\n",
    "            comboList.append((numericList[i], numericList[j]))\n",
    "\n",
    "    numCombos = len(comboList)\n",
    "\n",
    "    fig=plt.figure(figsize=(10,numCombos*4))\n",
    "    for i, (x, y) in enumerate(comboList):\n",
    "        ax=fig.add_subplot(numCombos,1,i+1)\n",
    "        sns.scatterplot(data=df, x=x, y=y, hue=colorLabel)\n",
    "        ax.set_title(f'{x} vs {y}') \n",
    "    fig.tight_layout()\n",
    "\n",
    "def categoricalCountPlots(df, categoricalList, colorLabel):\n",
    "    numFeats = len(categoricalList)\n",
    "    fig=plt.figure(figsize=(10,numFeats*4))\n",
    "    for i, var_name in enumerate(categoricalList):\n",
    "        ax=fig.add_subplot(numFeats,1,i+1)\n",
    "        sns.countplot(data=df, x=var_name, axes=ax, hue=colorLabel)\n",
    "        ax.set_title(var_name) \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "print(wd)\n",
    "sys.path.insert(0, wd)\n",
    "                \n",
    "import plotHelper as ph\n",
    "categoricalList=['HomePlanet', 'Destination', 'CryoSleep', 'VIP', 'ZeroExpense', 'GroupSize', 'FamilySize', 'CabinSize']\n",
    "categoricalList.extend(['CabinRegion', 'AgeDecile', 'Deck','Side', 'CabinNumLen']) # Cabin derived features\n",
    "categoricalCountPlots(trainProcessedDF, categoricalList, 'Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics=['CabinNum', 'GroupNum', 'Expenditure', 'LogExpenditure', 'Age']\n",
    "numericTuples=[('CabinNum', 20), ('GroupNum', 200), ('Expenditure',3000), ('LogExpenditure', 0.1), ('Age', 1)]\n",
    "\n",
    "def numericHistograms(df, numericList, colorLabel):\n",
    "    numNumerics = len(numericList)\n",
    "    fig=plt.figure(figsize=(10,numNumerics*4))\n",
    "    for i, (numeric, bw) in enumerate(numericList):\n",
    "        ax=fig.add_subplot(numNumerics,1,i+1)\n",
    "        sns.histplot(data=df, x=numeric, hue=colorLabel, binwidth=bw, kde=True)\n",
    "        ax.set_title(numeric) \n",
    "    fig.tight_layout()\n",
    "numericHistograms(trainProcessedDF, numericTuples, 'Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catCombo_Heatmap(df, comboList):\n",
    "    numCombos = len(comboList)\n",
    "    fig=plt.figure(figsize=(10,numCombos*4))\n",
    "    for i, (x, y) in enumerate(comboList):\n",
    "        gbdf=df.groupby([y, x])[x].size().unstack().fillna(0)\n",
    "        ax=fig.add_subplot(numCombos,1,i+1)\n",
    "        sns.heatmap(gbdf.T, annot=True, fmt='g', cmap='coolwarm')\n",
    "        ax.set_title(f'{x} vs {y}') \n",
    "    fig.tight_layout()\n",
    "\n",
    "combos = [('HomePlanet', 'Destination'), ('FamilySize', 'GroupSize'), ('CabinSize', 'GroupSize'), ('CabinSize', 'FamilySize')]\n",
    "catCombo_Heatmap(trainProcessedDF, combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For each family size, what is the PCTOFTOTAL of Transported?\n",
    "    FamSz=2: Pct=0, 0.5, 1.0\n",
    "    FamSz=3: Pct=[0,0.3, 0.6, 1.0]\n",
    "    FamSz=4: Pct=[0,0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "    [FamilySize][PercentOfTotal].size()\n",
    "    PctTotal is a groupbyFamily.\n",
    "    Count PctTotal is a groupby FamilySize\n",
    "\"\"\"\n",
    "\n",
    "trainProcessedDF['Ysum'] = trainProcessedDF.groupby(['LastName'])['Transported'].transform('sum')\n",
    "trainProcessedDF['Ysize'] = trainProcessedDF.groupby(['LastName'])['Transported'].transform('size')\n",
    "trainProcessedDF['Ypct'] = trainProcessedDF['Ysum'].div(trainProcessedDF['Ysize']).astype('str')\n",
    "gb = trainProcessedDF.groupby(['LastName'])['Ypct'].avg()\n",
    "print(trainProcessedDF[['LastName', 'FamilySize', 'Transported', 'Ypct', 'Ysum', 'Ysize']].sort_values(by=\"LastName\").head(n=60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catCombo_GbCountplot(df, comboList):\n",
    "    dfDict = {}\n",
    "    for tpl in comboList:\n",
    "        (y,x) = tpl\n",
    "        catCountDF = df.groupby([y, x])[x].size().unstack().fillna(0)\n",
    "        uniqueSeries = (catCountDF>0).sum(axis=1).reset_index(name='Count')['Count'].sort_values().astype(str)\n",
    "        dfDict[tpl] = uniqueSeries\n",
    "    numCombos = len(comboList)\n",
    "\n",
    "    for tpl, df in dfDict.items():\n",
    "        print(f\"{tpl} -> {df.shape}\")\n",
    "\n",
    "    fig=plt.figure(figsize=(10,numCombos*4))\n",
    "    for i, (tpl, dfgb) in enumerate(dfDict.items()):\n",
    "        (x,y) = tpl\n",
    "        ax=fig.add_subplot(numCombos,1,i+1)\n",
    "        sns.countplot(x=dfgb)\n",
    "        ax.set_title(f\"Unique {y} per {x}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "combos = [('GroupNum','Deck'), ('GroupNum', 'CabinNum'), ('GroupNum', 'Side'), ('GroupNum', 'HomePlanet'), ('GroupNum', 'Destination'), ('GroupNum', 'CryoSleep')]\n",
    "filteredDF = trainProcessedDF[trainProcessedDF['GroupSize'] > 1]\n",
    "catCombo_GbCountplot(filteredDF, combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "* Group members always share the same HomePlanet, and the same side.\n",
    "* Group members can have different cabins, decks, destinations, and cryosleep status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = [('LastName','Deck'), ('LastName', 'CabinNum'), ('LastName', 'Side'), ('LastName', 'HomePlanet'), ('LastName', 'Destination'), ('LastName', 'CryoSleep')]\n",
    "# filteredDF = trainProcessedDF[trainProcessedDF['FamilySize'] > 1]\n",
    "catCombo_GbCountplot(filteredDF, combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "* Family Members always come from the same home planet.\n",
    "* But they can differ among other attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygwalker as pyg\n",
    "pyg.walk(trainProcessedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "\n",
    "trainHF = h2o.H2OFrame(trainProcessedDF)\n",
    "testHF = h2o.H2OFrame(testProcessedDF)\n",
    "\n",
    "trainHF.describe()\n",
    "x = trainHF.columns\n",
    "y = \"Transported\"\n",
    "trainHF[y] = trainHF[y].asfactor()\n",
    "x.remove(y)\n",
    "\n",
    "\n",
    "from h2o.automl import H2OAutoML\n",
    "aml = H2OAutoML(max_models=10, seed=42, max_runtime_secs=7200, sort_metric='accuracy')\n",
    "aml.train(x=x, y=y, training_frame=trainHF)\n",
    "print(aml.leaderboard)\n",
    "\n",
    "# Raw: Accuracy 79.1 - 80.1%\n",
    "# Curated: Accuracy 79.4 - 80.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aml.leader.varimp(use_pandas=True))\n",
    "aml.leader.varimp_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
